---
title: "Prediction for Proper Weight-Lifting Exercise Data"
author: "Matthew Sedlar"
date: "January 20, 2016"
output: html_document
---

## Data

The data comes from a paper titled "Qualitative Activity Recognition of Weight Lifting Exercises." According to the authors:

> Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

The participants were wearing sensors on their arms, forearms, and waist (belt), and a sensor was placed on the dumbbell.

## Handling the Data

The data set contains 19,622 observations with 160 variables. First I split the data into a training and test set, split 60/40. 

```{r echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}

data <- read.csv("data/pml-training.csv", stringsAsFactors = F, na.strings=c("NA",""))

require(caret)

trainIndex <- createDataPartition(data$classe, p=.6, list=F)

train <- data[trainIndex,]
test <- data[-trainIndex, ]

```

In order to properly evaluate the variables, I had to clean up the data set, identifying and removing near-zero variables and columns with a large amount of missing values. 

```{r warning=FALSE, message=FALSE}

require(dplyr)

# convert to data frame table
train <- tbl_df(train)

# select variables matching the sensor descriptions
train <- train %>% select(classe, matches("belt|arm|forearm|dumbbell"))

# remove columns that contain more than 75% NAs
train <- train[,colSums(is.na(train)) < nrow(train) * .75]

# convert 'classe' into a factor
train$classe <- as.factor(train$classe)

```

After this process, also repeated for the test set, I ended up with 53 potential predictors for my outcome variable, "classe."

```{r echo=FALSE, warning=FALSE, message=FALSE}

# convert to data frame table
test <- tbl_df(test)

# select variables matching the sensor descriptions
test <- test %>% select(classe, matches("belt|arm|forearm|dumbbell"))

# remove columns that contain more than 75% NAs
test <- test[,colSums(is.na(test)) < nrow(test) * .75]

# convert 'classe' into a factor
test$classe <- as.factor(test$classe)

```

## Selecting an Algorithm

Since I was trying to predict a classification variable, I originally chose a CART model but was unable to get a satisfactory accuracy with the final model. I finally settled on Leo Breiman's Random Forests algorithm, which resulted in much better accuracy. However, I chose to use the randomForest package, not caret's train function because I found caret to be buggy and memory-instensive. These calculations were done on a Chromebook running Linux with very little processing power, so I had little patience with caret.

```{r echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}

require(randomForest)

set.seed(1234)
trees <- randomForest(classe ~., data=train)

```

## Cross-Validation

Because I used Random Forests, there was no reason to conduct cross-validation. As Breiman himself [points out](http://www.stat.berkeley.edu/~breiman/RandomForests/cc.home.htm#ooberr):

> Each tree is constructed using a different bootstrap sample from the original data. About one-third of the cases are left out of the bootstrap sample and not used in the construction of the kth tree.

## Results

The table below shows the confusion matrix for my model.

```{r echo=FALSE}

require(knitr)

pred <- predict(trees,test[,-1])
acc_table <- table(test$classe,pred)

kable(acc_table)


```